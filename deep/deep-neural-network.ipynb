{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "df = pd.read_csv(\"iris.data\",header=None, names=columns)\n",
    "\n",
    "# Preprocess the data\n",
    "X = df.drop('class', axis=1).values\n",
    "y = df['class'].values\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "\n",
    "y = y.astype(int)\n",
    "num_classes = len(np.unique(y))\n",
    "y_one_hot = np.eye(num_classes)[y]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.weights1 = np.random.randn(input_size, hidden_size)\n",
    "        self.biases1 = np.zeros((1, hidden_size))\n",
    "        self.weights2 = np.random.randn(hidden_size, output_size)\n",
    "        self.biases2 = np.zeros((1, output_size))\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.hidden_layer = self.sigmoid(np.dot(X, self.weights1) + self.biases1)\n",
    "        self.output_layer = self.sigmoid(np.dot(self.hidden_layer, self.weights2) + self.biases2)\n",
    "        return self.output_layer\n",
    "    \n",
    "    def backward(self, X, y, output):\n",
    "        self.output_error = y - output\n",
    "        self.output_delta = self.output_error * self.sigmoid_derivative(output)\n",
    "        self.hidden_error = np.dot(self.output_delta, self.weights2.T)\n",
    "        self.hidden_delta = self.hidden_error * self.sigmoid_derivative(self.hidden_layer)\n",
    "        self.weights1 += np.dot(X.T, self.hidden_delta)\n",
    "        self.biases1 += np.sum(self.hidden_delta, axis=0, keepdims=True)\n",
    "        self.weights2 += np.dot(self.hidden_layer.T, self.output_delta)\n",
    "        self.biases2 += np.sum(self.output_delta, axis=0, keepdims=True)\n",
    "        \n",
    "    def train(self, X, y, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.69656906e-05, 6.38936458e-06, 1.08555007e-04],\n",
       "       [3.71528924e-05, 6.43102763e-06, 1.08244382e-04],\n",
       "       [3.67696203e-05, 6.32946272e-06, 1.09166052e-04],\n",
       "       [3.69304192e-05, 6.37829853e-06, 1.08713651e-04],\n",
       "       [3.70062179e-05, 6.40305450e-06, 1.08338782e-04],\n",
       "       [3.72604870e-05, 6.45495833e-06, 1.08371970e-04],\n",
       "       [3.70158496e-05, 6.40374473e-06, 1.08589884e-04],\n",
       "       [3.69000888e-05, 6.37044263e-06, 1.08703120e-04],\n",
       "       [3.69849686e-05, 6.38988961e-06, 1.08818400e-04],\n",
       "       [3.70190226e-05, 6.40402626e-06, 1.08557429e-04],\n",
       "       [3.68635422e-05, 6.35895226e-06, 1.08841615e-04],\n",
       "       [3.74816483e-05, 6.48523104e-06, 1.08538251e-04],\n",
       "       [3.72833551e-05, 6.45111684e-06, 1.08318989e-04],\n",
       "       [3.73915111e-05, 6.47019278e-06, 1.08463257e-04],\n",
       "       [3.72851885e-05, 6.43821468e-06, 1.08238775e-04],\n",
       "       [3.69502847e-05, 6.38638050e-06, 1.08512736e-04],\n",
       "       [3.65112344e-05, 6.24795926e-06, 1.10220778e-04],\n",
       "       [3.70203280e-05, 6.40182119e-06, 1.08714026e-04],\n",
       "       [3.68957962e-05, 6.36638966e-06, 1.08905385e-04],\n",
       "       [3.64810458e-05, 6.23767110e-06, 1.10397147e-04],\n",
       "       [3.73909789e-05, 6.46544398e-06, 1.08444955e-04],\n",
       "       [3.68096243e-05, 6.34096059e-06, 1.09121383e-04],\n",
       "       [3.73037109e-05, 6.45660672e-06, 1.08387282e-04],\n",
       "       [3.65573085e-05, 6.26158007e-06, 1.10090570e-04],\n",
       "       [3.69800611e-05, 6.39709069e-06, 1.08293233e-04],\n",
       "       [3.68119428e-05, 6.34226322e-06, 1.09067148e-04],\n",
       "       [3.67892298e-05, 6.33381056e-06, 1.09199578e-04],\n",
       "       [3.66742533e-05, 6.29971582e-06, 1.09539344e-04],\n",
       "       [3.74914813e-05, 6.49480174e-06, 1.08602194e-04],\n",
       "       [3.73809627e-05, 6.47057079e-06, 1.08488176e-04],\n",
       "       [3.77675888e-05, 6.45717177e-06, 1.08139925e-04],\n",
       "       [3.71722835e-05, 6.42212903e-06, 1.08163120e-04],\n",
       "       [3.70141501e-05, 6.40626086e-06, 1.08286919e-04],\n",
       "       [3.73432628e-05, 6.45250194e-06, 1.08349740e-04],\n",
       "       [3.76670522e-05, 6.48451337e-06, 1.08449636e-04],\n",
       "       [3.67982285e-05, 6.33496787e-06, 1.09299188e-04],\n",
       "       [3.69866159e-05, 6.39762259e-06, 1.08392172e-04],\n",
       "       [3.72820989e-05, 6.44761428e-06, 1.08312236e-04],\n",
       "       [3.73541134e-05, 6.44726160e-06, 1.08273661e-04],\n",
       "       [3.72597492e-05, 6.42266563e-06, 1.08136940e-04],\n",
       "       [3.63911341e-05, 6.20797630e-06, 1.10881488e-04],\n",
       "       [3.69241704e-05, 6.37810040e-06, 1.08630012e-04],\n",
       "       [3.69970871e-05, 6.40096922e-06, 1.08336360e-04],\n",
       "       [3.72820467e-05, 6.44076794e-06, 1.08238583e-04],\n",
       "       [3.72338598e-05, 6.43825978e-06, 1.08257781e-04],\n",
       "       [3.70594799e-05, 6.41192052e-06, 1.08730517e-04],\n",
       "       [3.69033454e-05, 6.37015950e-06, 1.08756357e-04],\n",
       "       [3.67907040e-05, 6.33587526e-06, 1.09116954e-04],\n",
       "       [3.70121191e-05, 6.40520853e-06, 1.08320820e-04],\n",
       "       [3.67894531e-05, 6.33660313e-06, 1.09050382e-04],\n",
       "       [3.69489479e-05, 6.38346678e-06, 1.08707264e-04],\n",
       "       [3.68848101e-05, 6.36633385e-06, 1.08692804e-04],\n",
       "       [3.68096083e-05, 6.34015016e-06, 1.09198054e-04],\n",
       "       [3.73363682e-05, 6.45179638e-06, 1.08313684e-04],\n",
       "       [3.69031151e-05, 6.37192518e-06, 1.08630509e-04],\n",
       "       [3.70142338e-05, 6.40289156e-06, 1.08513725e-04],\n",
       "       [3.73223854e-05, 6.45590018e-06, 1.08350396e-04],\n",
       "       [3.74043690e-05, 6.46006379e-06, 1.08335376e-04],\n",
       "       [3.71844656e-05, 6.43154212e-06, 1.08260520e-04],\n",
       "       [3.71071105e-05, 6.41229042e-06, 1.09571333e-04],\n",
       "       [3.68665790e-05, 6.35774461e-06, 1.08963623e-04],\n",
       "       [3.72495406e-05, 6.44262096e-06, 1.08345810e-04],\n",
       "       [3.73525832e-05, 6.47320663e-06, 1.08517443e-04],\n",
       "       [3.72708259e-05, 6.45852442e-06, 1.08427374e-04],\n",
       "       [3.69281285e-05, 6.37524465e-06, 1.08895001e-04],\n",
       "       [3.73108330e-05, 6.45332064e-06, 1.08347342e-04],\n",
       "       [3.69630753e-05, 6.38850305e-06, 1.08609340e-04],\n",
       "       [3.69176714e-05, 6.37734544e-06, 1.08533587e-04],\n",
       "       [3.75178378e-05, 6.47686312e-06, 1.08455537e-04],\n",
       "       [3.70017243e-05, 6.40100500e-06, 1.08426880e-04],\n",
       "       [3.61604943e-05, 6.13431748e-06, 1.11950946e-04],\n",
       "       [3.72281776e-05, 6.42404778e-06, 1.08151926e-04],\n",
       "       [3.67932333e-05, 6.33563243e-06, 1.09203631e-04],\n",
       "       [3.63911341e-05, 6.20797630e-06, 1.10881488e-04],\n",
       "       [3.70779848e-05, 6.41767136e-06, 1.08581146e-04],\n",
       "       [3.67039393e-05, 6.30661535e-06, 1.09636683e-04],\n",
       "       [3.64614157e-05, 6.23293603e-06, 1.10400570e-04],\n",
       "       [3.69633217e-05, 6.38056192e-06, 1.09149652e-04],\n",
       "       [3.71827774e-05, 6.43174409e-06, 1.08239204e-04],\n",
       "       [3.70974591e-05, 6.41737618e-06, 1.09162776e-04],\n",
       "       [3.67710577e-05, 6.32811897e-06, 1.09290552e-04],\n",
       "       [3.73809849e-05, 6.46420454e-06, 1.08394648e-04],\n",
       "       [3.74851826e-05, 6.48146643e-06, 1.08456958e-04],\n",
       "       [3.70323812e-05, 6.40358378e-06, 1.08816881e-04],\n",
       "       [3.69616129e-05, 6.38955613e-06, 1.08477906e-04],\n",
       "       [3.73915111e-05, 6.47019278e-06, 1.08463257e-04],\n",
       "       [3.57416926e-05, 6.00727993e-06, 1.13533924e-04],\n",
       "       [3.73327615e-05, 6.45438464e-06, 1.08348906e-04],\n",
       "       [3.72982489e-05, 6.45747356e-06, 1.08394607e-04],\n",
       "       [3.67643814e-05, 6.32718174e-06, 1.09278618e-04],\n",
       "       [3.71318768e-05, 6.43198230e-06, 1.08909491e-04],\n",
       "       [3.67889141e-05, 6.33578495e-06, 1.09095072e-04],\n",
       "       [3.67556945e-05, 6.32266166e-06, 1.09393892e-04],\n",
       "       [3.67215602e-05, 6.31218383e-06, 1.09486580e-04],\n",
       "       [3.69327982e-05, 6.38135221e-06, 1.08518896e-04],\n",
       "       [3.69504597e-05, 6.37952481e-06, 1.09014441e-04],\n",
       "       [3.76587726e-05, 6.51018845e-06, 1.08695910e-04],\n",
       "       [3.79393804e-05, 6.51579218e-06, 1.08549620e-04],\n",
       "       [3.67985120e-05, 6.33172827e-06, 1.09475946e-04],\n",
       "       [3.69344171e-05, 6.38200387e-06, 1.08505476e-04],\n",
       "       [3.74809965e-05, 6.47950398e-06, 1.08514526e-04],\n",
       "       [3.73380353e-05, 6.45511832e-06, 1.08335390e-04],\n",
       "       [3.77054711e-05, 6.50649127e-06, 1.08613118e-04],\n",
       "       [3.69307805e-05, 6.37688809e-06, 1.08765866e-04],\n",
       "       [3.63534789e-05, 6.19929743e-06, 1.10819983e-04]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 10\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "nn = NeuralNetwork(input_size=input_dim, hidden_size=hidden_dim, output_size=output_dim)\n",
    "\n",
    "nn.train(X_train, y_train, epochs=150)\n",
    "nn.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
